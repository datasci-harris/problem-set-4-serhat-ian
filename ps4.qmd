---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    # Use only necessary LaTeX packages and configurations
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
# Set global execution options for Quarto
execute:
  echo: true
  eval: true
  warning: false
  message: false
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces=false,
      showtabs=false,
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points.

## Style Points (10 pts)

## Submission Steps (10 pts)

# Download and explore the Provider of Services (POS) file (10 pts)

1.  

| Variable | Definition |
|--------------------|:--------------------------------------------------------|
| PRVDR_CTGRY_SBTYP_CD | Identifies the subtype of the provider, within the primary category. Used to show the breakdown of provider categories, mainly for hospitals and SNFs. |
| PRVDR_CTGRY_CD | Identifies the type of provider participating in the Medicare/Medicaid program. |
| FAC_NAME | Name of the provider certified to participate in the Medicare and/or Medicaid programs. |
| PRVDR_NUM | Six or ten position identification number assigned to a certified provider (CMS Certification Number). |
| PGM_TRMNTN_CD | Indicates the current termination status for the provider. |
| ZIP_CD | Five-digit ZIP code for a provider's physical address. |

## 2.

### (a)

```{python}

import pandas as pd
file_path = (r'C:\\Users\\shefo\\GitHub\\problem-set-4-serhat-ian\\pos2016.csv')
df = pd.read_csv(file_path)
pos2016  = df[(df["PRVDR_CTGRY_SBTYP_CD"]==1) & (df["PRVDR_CTGRY_CD"]==1)]

    
```

The number of short term hospital in the filtered data.

```{python}
len(pos2016)
```

### (b)

There are 7245 short term hospital in the data. However, the article provided in the problem set claims there were 5000. This difference could be arised from the authors" choice which type of short term hospital they used in their research or in other words, how they classified the short term hospitals.

## 3.

```{python}

file_path = (r"C:\Users\shefo\GitHub\problem-set-4-serhat-ian\pos2017.csv")
df = pd.read_csv(file_path)
pos2017  = df[(df["PRVDR_CTGRY_SBTYP_CD"]==1) & (df["PRVDR_CTGRY_CD"]==1)]

file_path = (r"C:\Users\shefo\GitHub\problem-set-4-serhat-ian\pos2018.csv")
df = pd.read_csv(file_path)
pos2018  = df[(df["PRVDR_CTGRY_SBTYP_CD"]==1) & (df["PRVDR_CTGRY_CD"]==1)]

file_path = (r"C:\Users\shefo\GitHub\problem-set-4-serhat-ian\pos2019.csv")
df = pd.read_csv(file_path)
pos2019 = df[(df["PRVDR_CTGRY_SBTYP_CD"]==1) & (df["PRVDR_CTGRY_CD"]==1)]

pos2016["Year"] = 2016
pos2017["Year"] = 2017
pos2018["Year"] = 2018
pos2019["Year"] = 2019

pos2016["ZIP_CD"] = pos2016["ZIP_CD"].astype(int).astype(str)
pos2017["ZIP_CD"] = pos2017["ZIP_CD"].astype(int).astype(str)
pos2018["ZIP_CD"] = pos2018["ZIP_CD"].astype(int).astype(str)
pos2019["ZIP_CD"] = pos2019["ZIP_CD"].astype(int).astype(str)


combined_df = pd.concat([pos2016, pos2017, pos2018, pos2019], ignore_index=True)

```

```{python}

import altair as alt

num_hospitals_per_year = combined_df.groupby("Year").size().reset_index(name="Count")
print(num_hospitals_per_year)


alt.Chart(num_hospitals_per_year).mark_bar().encode(
  x=alt.X("Year:O", title="Year"),
  y=alt.Y("Count:Q", title="Short Term Hospital Number")
)

```

## 4.

### (a)

```{python}
unique_hospitals_per_year = combined_df.groupby("Year")["PRVDR_NUM"].nunique().reset_index(name="Unique_Hospitals")
print(unique_hospitals_per_year)
alt.Chart(unique_hospitals_per_year).mark_bar().encode(
    x=alt.X("Year:O", title="Year"),
    y=alt.Y("Unique_Hospitals:Q", title="Short Term Hospital Number")
   )
```


## Identify hospital closures in POS file (15 pts) (*)

## 1

```{python}
active_2016 = pos2016[pos2016['PGM_TRMNTN_CD'] == 0]
active_2017 = pos2017[pos2017['PGM_TRMNTN_CD'] == 0]
active_2018 = pos2018[pos2018['PGM_TRMNTN_CD'] == 0]
active_2019 = pos2019[pos2019['PGM_TRMNTN_CD'] == 0]

def provider_in_year(df, provider_num):
    row = df[df['PRVDR_NUM'] == provider_num]
    return not row.empty and row['PGM_TRMNTN_CD'].values[0] == 0


def determine_closure_year(provider_num):
 
    if not provider_in_year(active_2017, provider_num):
        return 2017
    elif not provider_in_year(active_2018, provider_num):
        return 2018
    elif not provider_in_year(active_2019, provider_num):
        return 2019
    return None  

active_2016_only = active_2016[active_2016['PGM_TRMNTN_CD'] == 0]


active_2016_only['Year_Closed'] = active_2016_only['PRVDR_NUM'].apply(determine_closure_year)


closed_hospitals = active_2016_only.dropna(subset=['Year_Closed']).reset_index(drop=True)


print(f"Number of suspected hospital closures: {len(closed_hospitals)}")
```

## 2

```{python}
print(closed_hospitals[['FAC_NAME', 'PRVDR_NUM', 'ZIP_CD', 'Year_Closed']].sort_values(by="FAC_NAME").head(10))

```

## 3

## 3.

```{python}


active_2016 = pos2016[(pos2016["PRVDR_CTGRY_CD"] == 1) & (pos2016["PRVDR_CTGRY_SBTYP_CD"] == 1) & (pos2016["PGM_TRMNTN_CD"] == 0)]
active_2017 = pos2017[(pos2017["PRVDR_CTGRY_CD"] == 1) & (pos2017["PRVDR_CTGRY_SBTYP_CD"] == 1) & (pos2017["PGM_TRMNTN_CD"] == 0)]
active_2018 = pos2018[(pos2018["PRVDR_CTGRY_CD"] == 1) & (pos2018["PRVDR_CTGRY_SBTYP_CD"] == 1) & (pos2018["PGM_TRMNTN_CD"] == 0)]
active_2019 = pos2019[(pos2019["PRVDR_CTGRY_CD"] == 1) & (pos2019["PRVDR_CTGRY_SBTYP_CD"] == 1) & (pos2019["PGM_TRMNTN_CD"] == 0)]

closed_in_2017 = active_2016[active_2016["PRVDR_NUM"].isin(active_2017["PRVDR_NUM"]) == False].copy()
closed_in_2017["Year_Closed"] = 2017

closed_in_2018 = active_2016[(active_2016["PRVDR_NUM"].isin(active_2017["PRVDR_NUM"]) == True) &
                             (active_2016["PRVDR_NUM"].isin(active_2018["PRVDR_NUM"]) == False)].copy()
closed_in_2018["Year_Closed"] = 2018

closed_in_2019 = active_2016[(active_2016["PRVDR_NUM"].isin(active_2018["PRVDR_NUM"]) == True) &
                             (active_2016["PRVDR_NUM"].isin(active_2019["PRVDR_NUM"]) == False)].copy()
closed_in_2019["Year_Closed"] = 2019


closures_df = pd.concat([closed_in_2017, closed_in_2018, closed_in_2019], ignore_index=True)


def is_potential_merger(row, active_hospitals_by_year):
    zip_code = row["ZIP_CD"]
    year_closed = row["Year_Closed"]
    next_year = year_closed + 1
    
    
    if str(next_year) in active_hospitals_by_year:
       
        current_count = active_hospitals_by_year[str(year_closed)].loc[active_hospitals_by_year[str(year_closed)]["ZIP_CD"] == zip_code].shape[0]
        next_count = active_hospitals_by_year[str(next_year)].loc[active_hospitals_by_year[str(next_year)]["ZIP_CD"] == zip_code].shape[0]
        
        
        return next_count >= current_count
    return False


active_hospitals_by_year = {
    "2016": active_2016,
    "2017": active_2017,
    "2018": active_2018,
    "2019": active_2019
}


closures_df["Is_Merger"] = closures_df.apply(is_potential_merger, axis=1, args=(active_hospitals_by_year,))
potential_mergers_df = closures_df[closures_df["Is_Merger"] == True]
confirmed_closures_df = closures_df[closures_df["Is_Merger"] == False]



```

### (a)

```{python}
print("Number of potential mergers/acquisitions:", len(potential_mergers_df))
```

### (b)

```{python}
print("Number of confirmed closures:", len(confirmed_closures_df))
```

### (c)

```{python}
print("Sample of confirmed closures:\n", confirmed_closures_df[["FAC_NAME", "ZIP_CD", "PRVDR_NUM", "Year_Closed"]].head(10))
```


# Download Census zip code shapefile (10 pt)

## 1.

| **File Type** | **Description** | **Typical File Size** |
|----------------|-------------------------------------|--------------------|
| **`.dbf`** | Stores tabular data with attributes for each feature. | Varies, but typically small (KBs to a few MBs). |
| **`.prj`** | Contains projection information for aligning the map. | Very small (usually a few KBs). |
| **`.shp`** | Holds geometry (points, lines, polygons) of the features. | Can be large (depends on data complexity, MBs to GBs). |
| **`.shx`** | An index file for quick access to shapes in the `.shp` file. | Small (usually a few KBs). |
| **`.xml`** | Metadata file with extra information about the dataset. | Small (a few KBs). |

## 2.

```{python}

import geopandas as gpd
import altair as alt
import matplotlib.pyplot as plt


shapefile_path = r"C:\Users\shefo\GitHub\problem-set-4-serhat-ian\gz_2010_us_860_00_500k.shp"
zip_gdf = gpd.read_file(shapefile_path)

zip_gdf["ZCTA5"] = zip_gdf["ZCTA5"].astype(str)  


texas_zip_gdf = zip_gdf[zip_gdf["ZCTA5"].str.startswith(("75", "76", "77", "78", "79"))]


texas_hospitals = pos2016[pos2016["ZIP_CD"].str.startswith(("75", "76", "77", "78", "79"))]


hospital_counts = texas_hospitals.groupby("ZIP_CD").size().reset_index(name="Hospital_Count")



merged_gdf = texas_zip_gdf.merge(hospital_counts, left_on="ZCTA5", right_on="ZIP_CD", how="left")

merged_gdf["Hospital_Count"] = merged_gdf["Hospital_Count"].fillna(0)
#I got a very weird map with so many blank areas. So I asked to ChatGPT what was the problem. It said this problem could arise from the NA values in hospital count column, so added the code line above to solve this. 

fig, ax = plt.subplots(figsize=(10, 8)) 

merged_gdf.plot(
    column="Hospital_Count",  
    cmap="Reds",              
    linewidth=0.8,             
    edgecolor="gray",          
    legend=True,               
    legend_kwds={"label": "Hospital Count"},  
    ax=ax                      
)

ax.set_title("Number of Short Term Hospitals by Zip Code in Texas (2016)", fontsize=15)
ax.axis("off") 

plt.show()

```


##part 4

```{python}

from shapely.geometry import shape, Point
import time
import fiona

zip_features = []

with fiona.open(r"C:\Users\shefo\GitHub\problem-set-4-serhat-ian\gz_2010_us_860_00_500k.shp") as src:
    for feature in src:
        zip_code = feature['properties']['ZCTA5']  
        geometry = shape(feature['geometry'])
        centroid = geometry.centroid
        zip_features.append({"ZIP_CODE": zip_code, "geometry": geometry, "centroid": centroid})

zips_all_centroids = gpd.GeoDataFrame(zip_features, geometry="centroid")
print("Dimensions of zips_all_centroids:", zips_all_centroids.shape)
print("Columns in zips_all_centroids:", zips_all_centroids.columns)

```
## 2.

```{python}
texas_prefixes = ["75", "76", "77", "78", "79"]
#Oklahoma zip code prexies 73 and 74
#New Mexico 870-884
#Arkansas 716-729
#Lousiana 700-715
bordering_prefixes = texas_prefixes +  ["73", "74", "870", "871", "872", "873", "874", "875",
    "876", "877", "878", "879", "880", "881", "882", "883", "884",
    "700", "701", "702", "703", "704", "705", "706", "707", "708", "709",
    "710", "711", "712", "713", "714", "715", "716", "717", "718", "719",
    "720", "721", "722", "723", "724", "725", "726", "727", "728", "729"
]

zips_texas_centroids = zips_all_centroids[zips_all_centroids["ZIP_CODE"].str.startswith(tuple(texas_prefixes))]
print("Unique Texas ZIP codes:", zips_texas_centroids["ZIP_CODE"].nunique())

zips_texas_borderstates_centroids = zips_all_centroids[zips_all_centroids["ZIP_CODE"].str.startswith(tuple(bordering_prefixes))]
print("Unique Texas + Bordering States ZIP codes:", zips_texas_borderstates_centroids["ZIP_CODE"].nunique())

```

```{python}

# Step 3: Create zips_withhospital_centroids Subset for ZIP Codes with Hospitals in 2016
# Example hospital data for 2016 (replace with actual data)

zips_with_hospitals_2016 = active_2016["ZIP_CD"].unique()

# Filter Texas and bordering states ZIP codes that have hospitals in 2016
zips_withhospital_centroids = zips_texas_borderstates_centroids[zips_texas_borderstates_centroids["ZIP_CODE"].isin(zips_with_hospitals_2016)]
print("Dimensions of zips_withhospital_centroids:", zips_withhospital_centroids.shape)
```

Explanation of Merge: We used an inner join (by filtering only those ZIPs that are in the hospital list) to identify ZIP codes with hospitals in 2016.

## 4.

```{python}

zips_texas_centroids["nearest_hospital_distance"] = zips_texas_centroids["centroid"].apply(
    lambda x: zips_withhospital_centroids.distance(x).min())

```

### (a)

```{python}
subset_texas_centroids = zips_texas_centroids.iloc[:10]

# Timing the subset for distance calculations
start_time = time.time()
subset_texas_centroids["nearest_hospital_distance"] = subset_texas_centroids["centroid"].apply(
    lambda x: zips_withhospital_centroids.distance(x).min()
)
end_time = time.time()
subset_time = end_time - start_time
print("Time for 10 ZIP code calculations:", subset_time, "seconds")

# Estimate the time for the full procedure
estimated_time_full = subset_time * (len(zips_texas_centroids) / 10)
print("Estimated time for full procedure:", estimated_time_full, "seconds")
```

### (b)

```{python}


# Full distance calculation for all Texas ZIP codes
start_time = time.time()
zips_texas_centroids["nearest_hospital_distance"] = zips_texas_centroids["centroid"].apply(
    lambda x: zips_withhospital_centroids.distance(x).min()
)
end_time = time.time()
actual_time_full = end_time - start_time
print("Actual time for full calculation:", actual_time_full, "seconds")

```

### (c)

```{python}
#
from pyproj import CRS

# Read the .prj file content as a WKT string
with open(r"C:\Users\shefo\GitHub\problem-set-4-serhat-ian\gz_2010_us_860_00_500k.prj") as file:
    prj_contents = file.read()

print("Contents of the .prj file:")
print(prj_contents)

```

Looking the content of the .prj file, we can see the unit is degree. The conversion will be done with the information from this site:https://gis.stackexchange.com/questions/142326/calculating-longitude-length-in-miles

Texas longtitude will be taken approixametly as 30.

```{python}
import math


def degrees_to_miles_longitude(distance_in_degrees, latitude=30):
    
    latitude_in_radians = latitude * 0.017453292519943295
    
    miles_per_degree_longitude = 69.172 * math.cos(latitude_in_radians)
    
    return distance_in_degrees * miles_per_degree_longitude


```

## 5.

```{python}

average_distance_degrees = zips_texas_centroids["nearest_hospital_distance"].mean()
print("Average distance to nearest hospital (in degrees):", average_distance_degrees)

```
### (a)

This is in degrees.

### (b)

```{python}

average_distance_miles = degrees_to_miles_longitude(average_distance_degrees, latitude=30)
print("Average distance to nearest hospital (in miles):", average_distance_miles)

```

### (c)

```{python}

zips_texas_centroids["nearest_hospital_distance_miles"] = zips_texas_centroids["nearest_hospital_distance"].apply(
    lambda x: degrees_to_miles_longitude(x, latitude=30)
)
import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 1, figsize=(10, 10))
zips_texas_centroids.plot(column="nearest_hospital_distance_miles", cmap="viridis", linewidth=0.8, ax=ax, edgecolor="0.8", legend=True)
plt.title("Distance to Nearest Hospital for Texas ZIP Codes (Miles)")
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.show()

```
